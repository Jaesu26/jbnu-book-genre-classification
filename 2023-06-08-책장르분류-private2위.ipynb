{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# (전북대학교 SW중심대학사업단) 2023년 인공지능 온라인 경진대회\n\n- 팀명: 펩시제로","metadata":{}},{"cell_type":"markdown","source":"`-` kaggle T4 GPU 사용\n\n`-` 코드는 크게 데이터 생성과 모델 적합으로 나뉘어져 있습니다\n\n`-` **OCR을 통한 책 커버의 글자 인식**과 **전처리-오타교정** 코드가 데이터 생성 코드로 해당 작업을 끝낸 후 메모리를 아끼기 위해 관련 코드를 주석 처리한 후 세션을 restart하여 모델을 적합했습니다 ","metadata":{"execution":{"iopub.status.busy":"2023-06-07T02:38:58.355712Z","iopub.execute_input":"2023-06-07T02:38:58.356519Z","iopub.status.idle":"2023-06-07T02:38:58.372017Z","shell.execute_reply.started":"2023-06-07T02:38:58.356483Z","shell.execute_reply":"2023-06-07T02:38:58.370574Z"}}},{"cell_type":"code","source":"!pip install lightning==2.0.2","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:39:33.498671Z","iopub.execute_input":"2023-06-05T09:39:33.49947Z","iopub.status.idle":"2023-06-05T09:39:52.575342Z","shell.execute_reply.started":"2023-06-05T09:39:33.499435Z","shell.execute_reply":"2023-06-05T09:39:52.573907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install easyocr==1.6.2","metadata":{"execution":{"iopub.status.busy":"2023-06-05T10:16:29.067066Z","iopub.execute_input":"2023-06-05T10:16:29.067702Z","iopub.status.idle":"2023-06-05T10:16:29.075519Z","shell.execute_reply.started":"2023-06-05T10:16:29.06765Z","shell.execute_reply":"2023-06-05T10:16:29.074586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 데이터 불러오기","metadata":{}},{"cell_type":"code","source":"import gc\nimport os\nimport warnings\nfrom typing import Dict, List, Optional, Tuple\n\nimport easydict\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:41:55.227932Z","iopub.execute_input":"2023-06-05T09:41:55.228398Z","iopub.status.idle":"2023-06-05T09:41:55.95077Z","shell.execute_reply.started":"2023-06-05T09:41:55.228347Z","shell.execute_reply":"2023-06-05T09:41:55.949826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/jbnu-swuniv-ai/train_data.csv\")\ntest = pd.read_csv(\"/kaggle/input/jbnu-swuniv-ai/test_data.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/jbnu-swuniv-ai/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:41:55.955895Z","iopub.execute_input":"2023-06-05T09:41:55.958262Z","iopub.status.idle":"2023-06-05T09:41:56.362337Z","shell.execute_reply.started":"2023-06-05T09:41:55.958223Z","shell.execute_reply":"2023-06-05T09:41:56.361374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 시각화","metadata":{}},{"cell_type":"code","source":"sns.countplot(data=df, y=\"label\", order=df[\"label\"].value_counts().index)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T18:34:28.691516Z","iopub.execute_input":"2023-05-30T18:34:28.691937Z","iopub.status.idle":"2023-05-30T18:34:29.282812Z","shell.execute_reply.started":"2023-05-30T18:34:28.691904Z","shell.execute_reply":"2023-05-30T18:34:29.281623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## OCR을 통한 책 커버의 글자 인식 ","metadata":{}},{"cell_type":"code","source":"import cv2\nimport easyocr\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-05-31T17:44:53.837824Z","iopub.execute_input":"2023-05-31T17:44:53.838486Z","iopub.status.idle":"2023-05-31T17:44:59.110167Z","shell.execute_reply.started":"2023-05-31T17:44:53.838441Z","shell.execute_reply":"2023-05-31T17:44:59.109153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ocr(paths: List[str]) -> List[str]:\n    reader = easyocr.Reader([\"en\"], gpu=True)\n    texts = []\n    for path in tqdm(paths):\n        image = cv2.imread(path)\n        image = np.asarray(Image.open(path).convert(\"L\")) if image is None else image\n        result = reader.readtext(image, batch_size=2048, detail=0)\n        text = \" \".join(result)\n        texts.append(text)\n    return texts","metadata":{"execution":{"iopub.status.busy":"2023-05-31T19:01:48.174915Z","iopub.execute_input":"2023-05-31T19:01:48.175308Z","iopub.status.idle":"2023-05-31T19:01:48.18247Z","shell.execute_reply.started":"2023-05-31T19:01:48.175276Z","shell.execute_reply":"2023-05-31T19:01:48.181401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- train images","metadata":{}},{"cell_type":"code","source":"base_path = \"/kaggle/input/jbnu-swuniv-ai/train\"\ntrain_paths = [\"/\".join([base_path, label, file_name]) for file_name, label in zip(df[\"Filename\"], df[\"label\"])]\ntrain_cover_texts = ocr(train_paths)\npd.DataFrame({\"Filename\": df[\"Filename\"].tolist(), \"Text\": train_cover_texts}).\\\nto_csv(\"/kaggle/working/train-book-cover-text.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T17:55:55.695481Z","iopub.execute_input":"2023-05-31T17:55:55.69587Z","iopub.status.idle":"2023-05-31T17:55:55.750457Z","shell.execute_reply.started":"2023-05-31T17:55:55.695835Z","shell.execute_reply":"2023-05-31T17:55:55.749457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- test images","metadata":{}},{"cell_type":"code","source":"base_path = \"/kaggle/input/jbnu-swuniv-ai/test\"\ntest_paths = [\"/\".join([base_path, file_name]) for file_name in test[\"Filename\"]]\ntest_cover_texts = ocr(test_paths)\npd.DataFrame({\"Filename\": test[\"Filename\"].tolist(), \"Text\": test_cover_texts}).\\\nto_csv(\"/kaggle/working/test-book-cover.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T19:00:47.866448Z","iopub.execute_input":"2023-05-31T19:00:47.866857Z","iopub.status.idle":"2023-05-31T19:00:47.884859Z","shell.execute_reply.started":"2023-05-31T19:00:47.866823Z","shell.execute_reply":"2023-05-31T19:00:47.883869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`-` 위 작업이 끝나면 /kaggle/working/train-book-cover-text.csv와 /kaggle/working/test-book-cover.csv파일이 생성됨\n\n`-` Add Data 버튼 오른쪽에 있는 Upload data를 통해 데이터 추가 (title은 book-cover, 경로는 book-cover/train.csv, book-cover/test.csv)\n\n`-` Add Data -> Your Datasets를 통해 book-cover 데이터셋을 추가","metadata":{}},{"cell_type":"markdown","source":"## 전처리","metadata":{}},{"cell_type":"markdown","source":"### 오타 교정","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2023-06-01T04:14:31.639283Z","iopub.execute_input":"2023-06-01T04:14:31.639799Z","iopub.status.idle":"2023-06-01T04:14:36.992978Z","shell.execute_reply.started":"2023-06-01T04:14:31.63976Z","shell.execute_reply":"2023-06-01T04:14:36.991643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SpellingCorrectionDataset(Dataset):\n    def __init__(self, texts, tokenizer, max_length=180):\n        self.texts = texts\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __getitem__(self, index):\n        text = self.texts[index]\n        token_ids = self.tokenizer.encode(\n            text,\n            padding=\"max_length\",\n            truncation=True,\n            max_length=self.max_length,\n            return_tensors=\"pt\",\n        )\n        token_ids = token_ids.squeeze(0)\n        return token_ids\n\n    def __len__(self):\n        return len(self.texts)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T04:16:57.526747Z","iopub.execute_input":"2023-06-01T04:16:57.527091Z","iopub.status.idle":"2023-06-01T04:16:57.535405Z","shell.execute_reply.started":"2023-06-01T04:16:57.527063Z","shell.execute_reply":"2023-06-01T04:16:57.534223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_cover_text(cover_text: pd.Series) -> pd.Series:\n    cover_text = cover_text.fillna(\"\")\n    cover_text = cover_text.apply(lambda x: x.lower())\n    return cover_text","metadata":{"execution":{"iopub.status.busy":"2023-06-01T04:16:57.766461Z","iopub.execute_input":"2023-06-01T04:16:57.76729Z","iopub.status.idle":"2023-06-01T04:16:57.772207Z","shell.execute_reply.started":"2023-06-01T04:16:57.767257Z","shell.execute_reply":"2023-06-01T04:16:57.771084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_token_ids_list(texts, model, tokenizer, max_length, batch_size, device):\n    dataset = SpellingCorrectionDataset(texts, tokenizer, max_length)  # bert-base-uncased의 경우 토큰 길이들의 99사분위수가 161\n    data_loader = DataLoader(dataset, batch_size=batch_size)\n    output_token_ids_list = []\n    with torch.no_grad():\n        for input_token_ids in tqdm(data_loader):\n            input_token_ids = input_token_ids.to(device)\n            output_token_ids = model.generate(input_token_ids)\n            output_token_ids = output_token_ids.cpu().squeeze(0).tolist()\n            output_token_ids_list.extend(output_token_ids)\n    return output_token_ids_list","metadata":{"execution":{"iopub.status.busy":"2023-06-01T04:16:57.989487Z","iopub.execute_input":"2023-06-01T04:16:57.989811Z","iopub.status.idle":"2023-06-01T04:16:57.997579Z","shell.execute_reply.started":"2023-06-01T04:16:57.989784Z","shell.execute_reply":"2023-06-01T04:16:57.996669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_token_ids_list(token_ids_list, tokenzier):\n    corrected_cover_texts = []\n    for token_ids in tqdm(token_ids_list):\n        corrected_cover_text = tokenizer.decode(token_ids, skip_special_tokens=True)\n        corrected_cover_texts.append(corrected_cover_text)\n    return corrected_cover_texts","metadata":{"execution":{"iopub.status.busy":"2023-06-01T04:56:41.197922Z","iopub.execute_input":"2023-06-01T04:56:41.198287Z","iopub.status.idle":"2023-06-01T04:56:41.206338Z","shell.execute_reply.started":"2023-06-01T04:56:41.198257Z","shell.execute_reply":"2023-06-01T04:56:41.205407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BS = 128\nmodel_name = \"oliverguhr/spelling-correction-english-base\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-06-01T04:14:37.047322Z","iopub.execute_input":"2023-06-01T04:14:37.047964Z","iopub.status.idle":"2023-06-01T04:14:37.122964Z","shell.execute_reply.started":"2023-06-01T04:14:37.047875Z","shell.execute_reply":"2023-06-01T04:14:37.121754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T17:17:50.540607Z","iopub.execute_input":"2023-06-04T17:17:50.541203Z","iopub.status.idle":"2023-06-04T17:17:50.544933Z","shell.execute_reply.started":"2023-06-04T17:17:50.541169Z","shell.execute_reply":"2023-06-04T17:17:50.544028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- train texts","metadata":{}},{"cell_type":"code","source":"train_book_cover = pd.read_csv(\"/kaggle/input/book-cover/train.csv\")\ntrain_book_cover[\"Text\"] = preprocess_cover_text(train_book_cover[\"Text\"])\ntrain_cover_texts = train_book_cover[\"Text\"].values\ntrain_output_token_ids_list = generate_token_ids_list(train_cover_texts, model, tokenizer, max_length=180, batch_size=BS, device=device)\ntrain_corrected_cover_texts = decode_token_ids_list(train_output_token_ids_list, tokenizer)\ntrain_book_cover[\"CorrectedText\"] = train_corrected_cover_texts\ntrain_book_cover.to_csv(\"/kaggle/working/train-corrected-book-cover.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T07:32:52.994152Z","iopub.execute_input":"2023-06-01T07:32:52.994531Z","iopub.status.idle":"2023-06-01T07:32:53.264512Z","shell.execute_reply.started":"2023-06-01T07:32:52.994499Z","shell.execute_reply":"2023-06-01T07:32:53.263494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- test texts","metadata":{}},{"cell_type":"code","source":"test_book_cover = pd.read_csv(\"/kaggle/input/book-cover/test.csv\")\ntest_book_cover[\"Text\"] = preprocess_cover_text(test_book_cover[\"Text\"])\ntest_cover_texts = test_book_cover[\"Text\"].values\ntest_output_token_ids_list = generate_token_ids_list(test_cover_texts, model, tokenizer, max_length=180, batch_size=BS, device=device)\ntest_corrected_cover_texts = decode_token_ids_list(test_output_token_ids_list, tokenizer)\ntest_book_cover[\"CorrectedText\"] = test_corrected_cover_texts \ntest_book_cover.to_csv(\"/kaggle/working/test-corrected-book-cover.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T04:58:48.531579Z","iopub.execute_input":"2023-06-01T04:58:48.532574Z","iopub.status.idle":"2023-06-01T04:58:48.635152Z","shell.execute_reply.started":"2023-06-01T04:58:48.532526Z","shell.execute_reply":"2023-06-01T04:58:48.634203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.cpu()\ndel model, tokenizer\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`-` 위 작업이 끝나면 /kaggle/working/train-corrected-book-cover-text.csv와 /kaggle/working/test-corrected-book-cover.csv파일이 생성됨\n\n`-` Add Data 버튼 오른쪽에 있는 Upload data를 통해 데이터 추가 (title은 corrected-book-cover, 경로는 corrected-book-cover/train.csv, corrected-book-cover/test.csv)\n\n`-` Add Data -> Your Datasets를 통해 corrected-book-cover 데이터셋을 추가\n\n`-` **이후 메모리를 아끼기 위해 데이터 생성 코드를 주석 처리하고 세션을 restart하여 모델을 적합**","metadata":{}},{"cell_type":"markdown","source":"### 데이터 병합","metadata":{}},{"cell_type":"code","source":"df = df.merge(pd.read_csv(\"/kaggle/input/corrected-book-cover/train.csv\"))\ntest = test.merge(pd.read_csv(\"/kaggle/input/corrected-book-cover/test.csv\"))","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:00.77834Z","iopub.execute_input":"2023-06-05T09:42:00.778727Z","iopub.status.idle":"2023-06-05T09:42:01.94753Z","shell.execute_reply.started":"2023-06-05T09:42:00.778695Z","shell.execute_reply":"2023-06-05T09:42:01.946511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 결측치 처리","metadata":{}},{"cell_type":"code","source":"df[\"Text\"] = df[\"Text\"].fillna(\"\")\ndf[\"CorrectedText\"] = df[\"CorrectedText\"].fillna(\"\")\n\ntest[\"Text\"] = test[\"Text\"].fillna(\"\")\ntest[\"CorrectedText\"] = test[\"CorrectedText\"].fillna(\"\")","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:01.949488Z","iopub.execute_input":"2023-06-05T09:42:01.949812Z","iopub.status.idle":"2023-06-05T09:42:01.987057Z","shell.execute_reply.started":"2023-06-05T09:42:01.949781Z","shell.execute_reply":"2023-06-05T09:42:01.986126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 타겟 레이블 인코딩","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:03.980303Z","iopub.execute_input":"2023-06-05T09:42:03.98117Z","iopub.status.idle":"2023-06-05T09:42:04.057936Z","shell.execute_reply.started":"2023-06-05T09:42:03.98113Z","shell.execute_reply":"2023-06-05T09:42:04.057111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ntargets = label_encoder.fit_transform(df[\"label\"].values)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:04.18774Z","iopub.execute_input":"2023-06-05T09:42:04.188026Z","iopub.status.idle":"2023-06-05T09:42:04.213564Z","shell.execute_reply.started":"2023-06-05T09:42:04.187995Z","shell.execute_reply":"2023-06-05T09:42:04.212665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 모델 학습 준비","metadata":{}},{"cell_type":"code","source":"import lightning.pytorch as pl\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom torch import Tensor\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics.classification import MulticlassF1Score\nfrom transformers import AdamW, AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:06.146939Z","iopub.execute_input":"2023-06-05T09:42:06.147972Z","iopub.status.idle":"2023-06-05T09:42:22.844211Z","shell.execute_reply.started":"2023-06-05T09:42:06.147928Z","shell.execute_reply":"2023-06-05T09:42:22.84332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 데이터","metadata":{}},{"cell_type":"code","source":"texts = df[\"Title\"].values\ncorrected_texts_pair = df[\"CorrectedText\"].values\n\ntest_texts = test[\"Title\"].values\ntest_corrected_texts_pair = test[\"CorrectedText\"].values","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:22.846341Z","iopub.execute_input":"2023-06-05T09:42:22.846661Z","iopub.status.idle":"2023-06-05T09:42:22.853952Z","shell.execute_reply.started":"2023-06-05T09:42:22.84663Z","shell.execute_reply":"2023-06-05T09:42:22.852766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 하이퍼파라미터","metadata":{}},{"cell_type":"code","source":"NUM_CLASSES = len(df[\"label\"].unique())","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:22.855664Z","iopub.execute_input":"2023-06-05T09:42:22.856244Z","iopub.status.idle":"2023-06-05T09:42:22.872214Z","shell.execute_reply.started":"2023-06-05T09:42:22.85621Z","shell.execute_reply":"2023-06-05T09:42:22.871358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = easydict.EasyDict({\n    \"weights_dirpath\": \"/kaggle/working/weights\",\n    \"num_classes\": NUM_CLASSES,\n    \"gradient_clip_val\": 2.0,\n    \"warmup_steps\": 0,\n    \"class_weight\": None,\n    \"label_smoothing\": 0.1,\n    \"max_epochs\": 4,\n    \"train_size\": 0.95,\n    \"log_interval\": 1,\n    \"seed\": 26,\n})","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:22.874795Z","iopub.execute_input":"2023-06-05T09:42:22.875231Z","iopub.status.idle":"2023-06-05T09:42:22.881291Z","shell.execute_reply.started":"2023-06-05T09:42:22.875196Z","shell.execute_reply":"2023-06-05T09:42:22.88016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args_bart = easydict.EasyDict(args)\nargs_bart.update({\n    \"model_name\": \"facebook/bart-large\",\n    \"max_length\": 59,\n    \"lr\": 3e-5,\n    \"batch_size\": 64,\n})\nargs_deberta = easydict.EasyDict(args)\nargs_deberta.update({\n    \"model_name\": \"microsoft/deberta-large\",\n    \"max_length\": 59,\n    \"max_epochs\": 2,\n    \"lr\": 2e-5,\n    \"batch_size\": 32,\n})\nargs_roberta = easydict.EasyDict(args)\nargs_roberta.update({\n    \"model_name\": \"roberta-large\",\n    \"max_length\": 59,\n    \"lr\": 3e-5,\n    \"batch_size\": 64,\n    \"seed\": 442,\n})\nargs_bert = easydict.EasyDict(args)\nargs_bert.update({\n    \"model_name\": \"bert-large-cased\",\n    \"warmup_steps\": 100,\n    \"max_length\": 65,\n    \"lr\": 3e-5,\n    \"batch_size\": 64,\n    \"seed\": 2023,\n})","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:22.882501Z","iopub.execute_input":"2023-06-05T09:42:22.883217Z","iopub.status.idle":"2023-06-05T09:42:22.894179Z","shell.execute_reply.started":"2023-06-05T09:42:22.883185Z","shell.execute_reply":"2023-06-05T09:42:22.893321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df, test","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:22.895532Z","iopub.execute_input":"2023-06-05T09:42:22.896037Z","iopub.status.idle":"2023-06-05T09:42:22.908059Z","shell.execute_reply.started":"2023-06-05T09:42:22.89598Z","shell.execute_reply":"2023-06-05T09:42:22.907134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 가중치 폴더 생성","metadata":{}},{"cell_type":"code","source":"def create_folder(path: str) -> None:\n    try:\n        if not os.path.exists(path):\n            os.makedirs(path)\n    except OSError as error:\n        print(error)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:22.911518Z","iopub.execute_input":"2023-06-05T09:42:22.911769Z","iopub.status.idle":"2023-06-05T09:42:22.920513Z","shell.execute_reply.started":"2023-06-05T09:42:22.911746Z","shell.execute_reply":"2023-06-05T09:42:22.919355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_folder(args.weights_dirpath)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:22.923673Z","iopub.execute_input":"2023-06-05T09:42:22.924496Z","iopub.status.idle":"2023-06-05T09:42:22.930537Z","shell.execute_reply.started":"2023-06-05T09:42:22.924465Z","shell.execute_reply":"2023-06-05T09:42:22.929426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 토큰 최대 길이 추정","metadata":{}},{"cell_type":"code","source":"# def get_token_length(tokenizer, text, max_length):\n#     fields = tokenizer(\n#         text,\n#         padding=\"max_length\",\n#         truncation=True,\n#         max_length=max_length,\n#         return_tensors=\"pt\",\n#     )\n#     length = fields[\"attention_mask\"].sum().item()\n#     return length","metadata":{"execution":{"iopub.status.busy":"2023-06-04T18:55:12.047348Z","iopub.execute_input":"2023-06-04T18:55:12.047733Z","iopub.status.idle":"2023-06-04T18:55:12.053311Z","shell.execute_reply.started":"2023-06-04T18:55:12.047702Z","shell.execute_reply":"2023-06-04T18:55:12.052209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(args_roberta.model_name)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T15:24:15.790097Z","iopub.execute_input":"2023-06-04T15:24:15.791062Z","iopub.status.idle":"2023-06-04T15:24:16.487191Z","shell.execute_reply.started":"2023-06-04T15:24:15.791014Z","shell.execute_reply":"2023-06-04T15:24:16.486003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lengths = []\n# for title, cover_text in tqdm(zip(df[\"Title\"], df[\"CorrectedText\"]), total=len(df)):\n#     title_length = get_token_length(tokenizer, title, max_length=100)\n#     cover_text_length = get_token_length(tokenizer, cover_text, max_length=1024)\n#     length = title_length + cover_text_length\n#     lengths.append(length)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T17:19:35.427275Z","iopub.execute_input":"2023-06-04T17:19:35.427668Z","iopub.status.idle":"2023-06-04T17:19:35.43182Z","shell.execute_reply.started":"2023-06-04T17:19:35.427616Z","shell.execute_reply":"2023-06-04T17:19:35.43085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.boxplot(lengths)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T17:19:34.073112Z","iopub.execute_input":"2023-06-04T17:19:34.073469Z","iopub.status.idle":"2023-06-04T17:19:34.077278Z","shell.execute_reply.started":"2023-06-04T17:19:34.073427Z","shell.execute_reply":"2023-06-04T17:19:34.07625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MAX_LENGTH = np.quantile(lengths, 0.99)\n# print(MAX_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T17:19:36.160331Z","iopub.execute_input":"2023-06-04T17:19:36.160914Z","iopub.status.idle":"2023-06-04T17:19:36.167014Z","shell.execute_reply.started":"2023-06-04T17:19:36.160879Z","shell.execute_reply":"2023-06-04T17:19:36.165778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# args[\"max_length\"] = int(MAX_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:37:09.89073Z","iopub.execute_input":"2023-06-02T12:37:09.891208Z","iopub.status.idle":"2023-06-02T12:37:09.898987Z","shell.execute_reply.started":"2023-06-02T12:37:09.891173Z","shell.execute_reply":"2023-06-02T12:37:09.897796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del tokenizer, lengths","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:37:09.900415Z","iopub.execute_input":"2023-06-02T12:37:09.901335Z","iopub.status.idle":"2023-06-02T12:37:09.921889Z","shell.execute_reply.started":"2023-06-02T12:37:09.901302Z","shell.execute_reply":"2023-06-02T12:37:09.920861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 가변 길이 처리","metadata":{}},{"cell_type":"code","source":"def tokenize(tokenizer, text, text_pair, max_length):\n    fields = tokenizer(\n        text, \n        text_pair,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=max_length,\n        return_tensors=\"pt\",\n        return_token_type_ids=True,\n    )\n    return fields[\"input_ids\"], fields['attention_mask'], fields['token_type_ids']\n\n\nclass TrainCollator:\n    def __init__(self, tokenizer, max_length):\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __call__(self, batch):\n        texts, texts_pair, labels = zip(*batch)\n        input_ids, attention_mask, token_type_ids = tokenize(self.tokenizer, texts, texts_pair, self.max_length)\n        labels = torch.tensor(labels)\n        return input_ids, attention_mask, token_type_ids, labels\n\n\nclass TestCollator:\n    def __init__(self, tokenizer, max_length):\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __call__(self, batch):\n        texts, texts_pair = zip(*batch)\n        input_ids, attention_mask, token_type_ids = tokenize(self.tokenizer, texts, texts_pair, self.max_length)\n        return input_ids, attention_mask, token_type_ids","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:22.932208Z","iopub.execute_input":"2023-06-05T09:42:22.932655Z","iopub.status.idle":"2023-06-05T09:42:22.942733Z","shell.execute_reply.started":"2023-06-05T09:42:22.932624Z","shell.execute_reply":"2023-06-05T09:42:22.941898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 데이터 모듈","metadata":{}},{"cell_type":"code","source":"class TrainTextDataset(Dataset):\n    def __init__(self, texts, texts_pair, labels):\n        self.texts = texts\n        self.texts_pair = texts_pair\n        self.labels = torch.tensor(labels, dtype=torch.int64)\n\n    def __getitem__(self, index):\n        text = self.texts[index]\n        text_pair = self.texts_pair[index]\n        label = self.labels[index]\n        return text, text_pair, label\n\n    def __len__(self):\n        return len(self.texts)\n\n\nclass TestTextDataset(Dataset):\n    def __init__(self, texts, texts_pair):\n        self.texts = texts\n        self.texts_pair = texts_pair\n\n    def __getitem__(self, index):\n        text = self.texts[index]\n        text_pair = self.texts_pair[index]\n        return text, text_pair\n\n    def __len__(self):\n        return len(self.texts)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:22.946412Z","iopub.execute_input":"2023-06-05T09:42:22.946689Z","iopub.status.idle":"2023-06-05T09:42:22.957889Z","shell.execute_reply.started":"2023-06-05T09:42:22.946666Z","shell.execute_reply":"2023-06-05T09:42:22.956929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        texts: np.ndarray,\n        texts_pair: np.ndarray,\n        labels: np.ndarray,\n        predict_texts: np.ndarray,\n        predict_texts_pair: np.ndarray,\n        model_name: str,\n        max_length: int = 59,\n        train_size: float = 0.95,\n        batch_size: int = 64,\n        seed: int = 26,\n    ) -> None:\n        super().__init__()\n        self.save_hyperparameters(ignore=[\"texts\", \"texts_pair\", \"labels\", \"predict_texts\", \"predict_texts_pair\"])\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.texts = texts\n        self.texts_pair = texts_pair\n        self.labels = labels\n        self.predict_texts = predict_texts\n        self.predict_texts_pair = predict_texts_pair\n        self.train_collator = TrainCollator(tokenizer, max_length)\n        self.test_collator = TestCollator(tokenizer, max_length)\n        self.train_dataset = None\n        self.val_dataset = None\n        self.predict_dataset = None\n\n    def setup(self, stage: str) -> None:\n        if stage == \"fit\":\n            train_texts, val_texts, train_texts_pair, val_texts_pair, train_labels, val_labels = train_test_split(\n                self.texts,\n                self.texts_pair,\n                self.labels,\n                train_size=self.hparams.train_size,\n                random_state=self.hparams.seed,\n                stratify=self.labels,\n            )\n            self.train_dataset = TrainTextDataset(train_texts, train_texts_pair, train_labels)\n            self.val_dataset = TrainTextDataset(val_texts, val_texts_pair, val_labels)\n        elif stage == \"predict\":\n            self.predict_dataset = TestTextDataset(self.predict_texts, self.predict_texts_pair)\n\n    def train_dataloader(self) -> DataLoader:\n        return DataLoader(self.train_dataset, batch_size=self.hparams.batch_size, shuffle=True, collate_fn=self.train_collator)\n\n    def val_dataloader(self) -> DataLoader:\n        return DataLoader(self.val_dataset, batch_size=self.hparams.batch_size, collate_fn=self.train_collator)\n\n    def predict_dataloader(self) -> DataLoader:\n        return DataLoader(self.predict_dataset, batch_size=self.hparams.batch_size * 8, collate_fn=self.test_collator)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:40.576673Z","iopub.execute_input":"2023-06-05T09:42:40.577104Z","iopub.status.idle":"2023-06-05T09:42:40.591732Z","shell.execute_reply.started":"2023-06-05T09:42:40.577048Z","shell.execute_reply":"2023-06-05T09:42:40.590014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 장르 분류 모델","metadata":{}},{"cell_type":"code","source":"class GenreClassifier(pl.LightningModule):\n    def __init__(\n        self,\n        model_name: str,\n        num_classes: int,\n        lr: float = 2e-5,\n        warmup_steps: int = 0,\n        weight: Optional[Tensor] = None,\n        label_smoothing: float = 0.0,\n        log_interval: int = 10,\n        seed: int = 26,\n    ) -> None:\n        super().__init__()\n        pl.seed_everything(seed)\n        self.save_hyperparameters()\n        self.net = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes, ignore_mismatched_sizes=True)\n        self.criterion = nn.CrossEntropyLoss(weight=weight, label_smoothing=label_smoothing)\n        self.macro_f1 = MulticlassF1Score(num_classes=num_classes, average=\"macro\")\n\n    def forward(self, input_ids: Tensor, attention_mask: Tensor, token_type_ids: Tensor) -> Tensor:\n        return self.net(input_ids, attention_mask, token_type_ids).logits\n\n    def training_step(self, batch: Tuple[Tensor, Tensor, Tensor, Tensor], batch_idx: int) -> Tensor:\n        *inputs, targets = batch\n        logits = self(*inputs)\n        loss = self.criterion(logits, targets)\n        return loss\n\n    def validation_step(self, batch: Tuple[Tensor, Tensor, Tensor, Tensor], batch_idx: int) -> None:\n        *inputs, targets = batch\n        logits = self(*inputs)\n        preds = logits.argmax(1)\n        self.macro_f1.update(preds, targets)\n\n    def on_validation_epoch_end(self) -> None:\n        macro_f1 = self.macro_f1.compute()\n        self.log(\"val_macro_f1\", macro_f1)\n        self.macro_f1.reset()\n        if self.should_log:\n            print(f\"Epoch {self.current_epoch + 1} | Val Macro F1: {macro_f1:.4f}\")\n\n    def predict_step(self, batch: Tuple[Tensor, Tensor, Tensor], batch_idx: int, dataloader_idx: int = 0) -> Tensor:\n        return self(*batch)\n\n    @property\n    def should_log(self) -> bool:\n        return (\n            self.current_epoch == 0\n            or (self.current_epoch + 1) % self.hparams.log_interval == 0\n            or self.current_epoch + 1 == self.trainer.max_epochs\n        )\n\n    def configure_optimizers(self) -> Tuple[List[optim.Optimizer], List[optim.lr_scheduler.LRScheduler]]:\n        optimizer = AdamW(self.parameters(), lr=self.hparams.lr, eps=1e-8, weight_decay=0.01)\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=self.hparams.warmup_steps,\n            num_training_steps=self.trainer.estimated_stepping_batches,\n        )\n        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n        return [optimizer], [scheduler]","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:22.974785Z","iopub.execute_input":"2023-06-05T09:42:22.976506Z","iopub.status.idle":"2023-06-05T09:42:22.995168Z","shell.execute_reply.started":"2023-06-05T09:42:22.976474Z","shell.execute_reply":"2023-06-05T09:42:22.994135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 모델 학습 및 예측","metadata":{}},{"cell_type":"code","source":"def fit_predict_proba(\n    texts,\n    texts_pair,\n    targets,\n    predict_texts,\n    predict_texts_pair,\n    args,\n):\n    gc.collect()\n    torch.cuda.empty_cache()\n    text_datamodule = TextDataModule(\n        texts,\n        texts_pair,\n        targets,\n        predict_texts,\n        predict_texts_pair,\n        model_name=args.model_name,\n        max_length=args.max_length,\n        train_size=args.train_size,\n        batch_size=args.batch_size,\n        seed=args.seed,\n    )\n    genre_classifier = GenreClassifier(\n        model_name=args.model_name,\n        num_classes=args.num_classes,\n        lr=args.lr,\n        warmup_steps=args.warmup_steps,\n        weight=args.class_weight,\n        label_smoothing=args.label_smoothing,\n        log_interval=args.log_interval,\n        seed=args.seed,\n    )\n    checkpoint = ModelCheckpoint(\n        dirpath=args.weights_dirpath,\n        filename=args.model_name,\n        monitor=\"val_macro_f1\",\n        mode=\"max\",\n        save_weights_only=True,\n    )\n    early_stopping = EarlyStopping(\n        monitor=\"val_macro_f1\",\n        patience=1,\n        mode=\"max\",\n    )\n    trainer = pl.Trainer(\n        accelerator=\"gpu\",\n        devices=1,\n        precision=16,\n        logger=False,\n        callbacks=[checkpoint, early_stopping],\n        max_epochs=args.max_epochs,\n        num_sanity_val_steps=0,\n        enable_progress_bar=True, \n        enable_model_summary=False,\n        gradient_clip_val=args.gradient_clip_val,\n        deterministic=True,\n    )\n    trainer.fit(genre_classifier, text_datamodule)\n    logits = trainer.predict(genre_classifier, text_datamodule, ckpt_path=\"best\")\n    logits = torch.cat(logits).float()\n    probs = F.softmax(logits, dim=1)\n    trainer.predict_loop._predictions = []\n    del logits, text_datamodule, genre_classifier, checkpoint, early_stopping, trainer\n    gc.collect()\n    torch.cuda.empty_cache()\n    return probs","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:22.998482Z","iopub.execute_input":"2023-06-05T09:42:22.998775Z","iopub.status.idle":"2023-06-05T09:42:23.012192Z","shell.execute_reply.started":"2023-06-05T09:42:22.998752Z","shell.execute_reply":"2023-06-05T09:42:23.01131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"ONEDNN_PRIMITIVE_CACHE_CAPACITY\"] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:23.015137Z","iopub.execute_input":"2023-06-05T09:42:23.015455Z","iopub.status.idle":"2023-06-05T09:42:23.025576Z","shell.execute_reply.started":"2023-06-05T09:42:23.015429Z","shell.execute_reply":"2023-06-05T09:42:23.024577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- bart","metadata":{}},{"cell_type":"code","source":"probs_bart = fit_predict_proba(texts, corrected_texts_pair, targets, test_texts, test_corrected_texts_pair, args_bart)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:49:56.573762Z","iopub.execute_input":"2023-06-05T09:49:56.575855Z","iopub.status.idle":"2023-06-05T09:53:11.748992Z","shell.execute_reply.started":"2023-06-05T09:49:56.575822Z","shell.execute_reply":"2023-06-05T09:53:11.747875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- roberta","metadata":{}},{"cell_type":"code","source":"probs_roberta = fit_predict_proba(texts, corrected_texts_pair, targets, test_texts, test_corrected_texts_pair, args_roberta)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:42:48.150638Z","iopub.execute_input":"2023-06-05T09:42:48.151223Z","iopub.status.idle":"2023-06-05T09:46:06.422152Z","shell.execute_reply.started":"2023-06-05T09:42:48.151189Z","shell.execute_reply":"2023-06-05T09:46:06.421051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:46:06.424253Z","iopub.execute_input":"2023-06-05T09:46:06.424566Z","iopub.status.idle":"2023-06-05T09:46:06.858356Z","shell.execute_reply.started":"2023-06-05T09:46:06.42453Z","shell.execute_reply":"2023-06-05T09:46:06.857374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- deberta","metadata":{}},{"cell_type":"code","source":"probs_deberta = fit_predict_proba(texts, corrected_texts_pair, targets, test_texts, test_corrected_texts_pair, args_deberta)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:46:06.859735Z","iopub.execute_input":"2023-06-05T09:46:06.860201Z","iopub.status.idle":"2023-06-05T09:49:56.236411Z","shell.execute_reply.started":"2023-06-05T09:46:06.860166Z","shell.execute_reply":"2023-06-05T09:49:56.235454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:49:56.239Z","iopub.execute_input":"2023-06-05T09:49:56.239428Z","iopub.status.idle":"2023-06-05T09:49:56.572173Z","shell.execute_reply.started":"2023-06-05T09:49:56.239394Z","shell.execute_reply":"2023-06-05T09:49:56.571145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- bert","metadata":{}},{"cell_type":"code","source":"probs_bert = fit_predict_proba(texts, corrected_texts_pair, targets, test_texts, test_corrected_texts_pair, args_bert)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T09:53:12.161831Z","iopub.execute_input":"2023-06-05T09:53:12.162232Z","iopub.status.idle":"2023-06-05T10:01:32.207986Z","shell.execute_reply.started":"2023-06-05T09:53:12.162196Z","shell.execute_reply":"2023-06-05T10:01:32.206706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-06-05T10:01:32.213604Z","iopub.execute_input":"2023-06-05T10:01:32.21405Z","iopub.status.idle":"2023-06-05T10:01:32.602704Z","shell.execute_reply.started":"2023-06-05T10:01:32.214017Z","shell.execute_reply":"2023-06-05T10:01:32.601797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 앙상블 및 제출","metadata":{}},{"cell_type":"markdown","source":"- soft voting","metadata":{}},{"cell_type":"code","source":"preds = (probs_roberta + probs_bart + probs_deberta + probs_bert).argmax(1).numpy()","metadata":{"execution":{"iopub.status.busy":"2023-06-05T06:06:38.299034Z","iopub.execute_input":"2023-06-05T06:06:38.2994Z","iopub.status.idle":"2023-06-05T06:06:38.318324Z","shell.execute_reply.started":"2023-06-05T06:06:38.299368Z","shell.execute_reply":"2023-06-05T06:06:38.317392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- submission","metadata":{}},{"cell_type":"code","source":"submission[\"label\"] = label_encoder.inverse_transform(preds)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T01:01:24.42225Z","iopub.execute_input":"2023-06-05T01:01:24.422669Z","iopub.status.idle":"2023-06-05T01:01:24.430034Z","shell.execute_reply.started":"2023-06-05T01:01:24.422635Z","shell.execute_reply":"2023-06-05T01:01:24.429101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-05T07:28:28.9318Z","iopub.execute_input":"2023-06-05T07:28:28.932294Z","iopub.status.idle":"2023-06-05T07:28:28.947623Z","shell.execute_reply.started":"2023-06-05T07:28:28.932247Z","shell.execute_reply":"2023-06-05T07:28:28.94638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T07:28:43.64903Z","iopub.execute_input":"2023-06-05T07:28:43.649425Z","iopub.status.idle":"2023-06-05T07:28:43.737098Z","shell.execute_reply.started":"2023-06-05T07:28:43.649395Z","shell.execute_reply":"2023-06-05T07:28:43.736167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}